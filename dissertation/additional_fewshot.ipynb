{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Fewshot Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code used to benchmark additional fewshot examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "load_dotenv()\n",
    "import pandas as pd\n",
    "import time\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "client = Mistral(\n",
    "\tapi_key=os.getenv('MISTRAL_API_KEY')\n",
    ")\n",
    "client_gpt = OpenAI(\n",
    "\tapi_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user_prompt</th>\n",
       "      <th>function_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>['immigrants']</td>\n",
       "      <td>0</td>\n",
       "      <td>Your goal is to classify text as either 'hatef...</td>\n",
       "      <td>glad not to live in ca. taxpayers pay over 13%...</td>\n",
       "      <td>few_shot_basic_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>['immigrants']</td>\n",
       "      <td>0</td>\n",
       "      <td>Your goal is to classify text as either 'hatef...</td>\n",
       "      <td>glad not to live in ca. taxpayers pay over 13%...</td>\n",
       "      <td>few_shot_basic_seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>['immigrants']</td>\n",
       "      <td>1</td>\n",
       "      <td>Your goal is to classify text as either 'hatef...</td>\n",
       "      <td>send all illegals away. no need to \"\"learn mor...</td>\n",
       "      <td>few_shot_basic_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>implicit_hate</td>\n",
       "      <td>['immigrants']</td>\n",
       "      <td>1</td>\n",
       "      <td>Your goal is to classify text as either 'hatef...</td>\n",
       "      <td>send all illegals away. no need to \"\"learn mor...</td>\n",
       "      <td>few_shot_basic_seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>not_hate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Your goal is to classify text as either 'hatef...</td>\n",
       "      <td>it is not racist and you are not a hate group ...</td>\n",
       "      <td>few_shot_basic_random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          class          target  id  \\\n",
       "0           0  implicit_hate  ['immigrants']   0   \n",
       "1           1  implicit_hate  ['immigrants']   0   \n",
       "2           2  implicit_hate  ['immigrants']   1   \n",
       "3           3  implicit_hate  ['immigrants']   1   \n",
       "4           4       not_hate             NaN   2   \n",
       "\n",
       "                                       system_prompt  \\\n",
       "0  Your goal is to classify text as either 'hatef...   \n",
       "1  Your goal is to classify text as either 'hatef...   \n",
       "2  Your goal is to classify text as either 'hatef...   \n",
       "3  Your goal is to classify text as either 'hatef...   \n",
       "4  Your goal is to classify text as either 'hatef...   \n",
       "\n",
       "                                         user_prompt          function_name  \n",
       "0  glad not to live in ca. taxpayers pay over 13%...  few_shot_basic_random  \n",
       "1  glad not to live in ca. taxpayers pay over 13%...    few_shot_basic_seed  \n",
       "2  send all illegals away. no need to \"\"learn mor...  few_shot_basic_random  \n",
       "3  send all illegals away. no need to \"\"learn mor...    few_shot_basic_seed  \n",
       "4  it is not racist and you are not a hate group ...  few_shot_basic_random  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./prompts_fewshot.tsv', sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(system_prompt, user_prompt, model, max_retries=5, temperature=0.01):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            completion = client.chat.complete(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={ \"type\": \"json_object\" }\n",
    "            )\n",
    "            content = completion.choices[0].message.content\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            wait_time = 2 ** retries\n",
    "            print(f\"Rate limit hit. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "    print(\"Max retries exceeded.\")\n",
    "    return \"No response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_gpt(system_prompt, user_prompt, max_retries=5, temperature=0.01):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            completion = client_gpt.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={ \"type\": \"json_object\" }\n",
    "            )\n",
    "            content = completion.choices[0].message.content\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            wait_time = 2 ** retries\n",
    "            print(f\"Rate limit hit. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "    print(\"Max retries exceeded.\")\n",
    "    return \"No response\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [1:09:41<00:00,  1.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load previously saved results if they exist\n",
    "output_file = 'results_gpt_fewshot.csv'\n",
    "\n",
    "# Check if the file exists, and if so, load the saved progress\n",
    "if os.path.exists(output_file):\n",
    "    processed_df = pd.read_csv(output_file)\n",
    "    processed_indices = set(processed_df['index'])\n",
    "    results = processed_df.to_dict(orient='records')\n",
    "    print(f\"Resuming from {len(results)} processed rows.\")\n",
    "else:\n",
    "    results = []\n",
    "    processed_indices = set()\n",
    "\n",
    "# Iterate over the DataFrame and process remaining rows\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    if index in processed_indices:\n",
    "        # Skip rows that have already been processed\n",
    "        continue\n",
    "    \n",
    "    model_output = classify_text_gpt(row['system_prompt'], row['user_prompt'])\n",
    "\n",
    "    # Append the result to the list\n",
    "    results.append({\n",
    "        'index': index,\n",
    "        'output': model_output\n",
    "    })\n",
    "\n",
    "    # Save results to CSV after each iteration to ensure progress is saved\n",
    "    pd.DataFrame(results).to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1418/3000 [35:35<39:06,  1.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit hit. Retrying in 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1640/3000 [46:59<28:59,  1.28s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit hit. Retrying in 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [1:21:56<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load previously saved results if they exist\n",
    "output_file = 'results_mistral_fewshot.csv'\n",
    "\n",
    "# Check if the file exists, and if so, load the saved progress\n",
    "if os.path.exists(output_file):\n",
    "    processed_df = pd.read_csv(output_file)\n",
    "    processed_indices = set(processed_df['index'])\n",
    "    results = processed_df.to_dict(orient='records')\n",
    "    print(f\"Resuming from {len(results)} processed rows.\")\n",
    "else:\n",
    "    results = []\n",
    "    processed_indices = set()\n",
    "\n",
    "# Iterate over the DataFrame and process remaining rows\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    if index in processed_indices:\n",
    "        # Skip rows that have already been processed\n",
    "        continue\n",
    "    \n",
    "    model_output = classify_text(row['system_prompt'], row['user_prompt'], model=\"mistral-large-latest\")\n",
    "\n",
    "    # Append the result to the list\n",
    "    results.append({\n",
    "        'index': index,\n",
    "        'output': model_output\n",
    "    })\n",
    "\n",
    "    # Save results to CSV after each iteration to ensure progress is saved\n",
    "    pd.DataFrame(results).to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
